Extended Audit: Use Case Gates Logical Consistency
Looking at the screenshot and the confirmed findings, I see a structural disconnect between how governance is conceived vs. implemented:
What I See in the Screenshot:
Governance Gates: 33% Complete
â”œâ”€â”€ Operating Model: Not Started
â”œâ”€â”€ Intake & Prioritisation: Waiting (blocked by Operating Model)
â”œâ”€â”€ Responsible AI: Waiting (blocked by Intake)
â””â”€â”€ Activate: Locked (requires all 3 gates)
And in the "Hexaware Portfolio Selection" section:
Activation blocked: Complete all 3 governance gates before activating this use case
â”œâ”€â”€ Operating Model (0%)
â”œâ”€â”€ Intake & Prioritisation (100%)  â† Inconsistent with "Waiting" above
â””â”€â”€ Responsible AI (0%)

âš ï¸ Additional Logical Inconsistencies with Use Case Gates
6. Gate Field Requirements are Hardcoded, Not Engagement-Scoped
Issue: Per replit.md, the gates are calculated from hardcoded field checks:
GateRequired Fields (Hardcoded)Operating ModelPrimary Business Owner, Use Case Status (â‰  Discovery), Business FunctionIntake & PrioritisationAll 10 scoring levers (1-5 range, 0 = incomplete)Responsible AIAll 5 RAI fields answered
Expected Behavior (per your architecture): If each engagement has its own governance setup, then:

Which fields are required for each gate should be configurable per engagement
Which gates exist should be configurable (some engagements might only need 2 gates)
Gate sequence might differ per client (e.g., RAI-first vs. Intake-first)

Current Impact: All engagements share identical gate requirements, which defeats the purpose of engagement-level governance configuration.

7. Two Separate Governance Concepts Conflated
Issue: The codebase has two governance concepts that aren't clearly separated:
ConceptPurposeWhere StoredGovernance BodiesOrganizational review committees (Ethical SteerCo, Working Group)tomConfig.governanceBodies in global metadataUse Case GatesField completeness checks for portfolio activationCalculated dynamically from use case fields
Expected Behavior: These should be distinct:

Governance Bodies = WHO approves (committees, roles)
Use Case Gates = WHAT criteria must be met (field completeness)

Both should be engagement-scoped, but currently:

Governance Bodies: Global (from metadata)
Gate Criteria: Hardcoded (not configurable at all)


8. Sequential Gate Blocking Creates UX Friction
Issue: The UI shows "Waiting" status with lock icons for gates blocked by prerequisites. Looking at the screenshot:

Intake & Prioritisation shows "Waiting" in the stepper
But the Portfolio Selection shows "100%" for the same gate

This is contradictory â€” if Intake is 100% complete, why is it "Waiting"?
Root Cause: The sequential logic enforces Operating Model â†’ Intake â†’ RAI order, so even if Intake fields are 100% filled, it shows "Waiting" because Operating Model isn't done.
UX Problem: Users can't understand why a "100% complete" gate is blocked. The logic should either:

Show actual completion % regardless of sequence, OR
Show "Blocked by Operating Model" explicitly instead of "Waiting"


9. "Active Portfolio" Logic Inconsistent with Engagement Scope
Issue: Per the audit, the Active Portfolio filter is:
isActiveForRsa === 'true' OR passes governance gates
But if governance gates are global and not engagement-specific, then use cases from different engagements are evaluated against the same criteria.
Example Problem:

Engagement A (Markel - strict insurance) requires all 5 RAI fields
Engagement B (Internal Hexaware) only needs 2 RAI fields
Currently, both are evaluated against the same global 5-field requirement
Internal Hexaware use cases might never reach "Active Portfolio" because they fail an irrelevant gate


Complete Inconsistency Summary
#IssueScope ImpactPriority1Value/Capability configs not engagement-scopedMulti-tenant brokenğŸ”´ High2TOM disabled by default despite preset selectionUX confusionğŸŸ¡ Medium3Governance Bodies global, not engagement-scopedMulti-tenant brokenğŸ”´ High4Capability not auto-derived on createEmpty dashboardsğŸŸ¡ Medium5Statusâ†’Phase mappingâœ… Working correctlyâ€”6Gate field requirements hardcodedMulti-tenant brokenğŸ”´ High7Governance Bodies vs Gates conflatedConceptual confusionğŸŸ¡ Medium8Sequential gate UX shows contradictory %User confusionğŸŸ¡ Medium9Active Portfolio filter uses global gatesMulti-tenant brokenğŸ”´ High

Recommended Engagement-Scoped Governance Model
To achieve true engagement-level configurability, I recommend this schema extension:
typescript// In engagements table or engagement metadata
interface EngagementGovernanceConfig {
  // What gates exist for this engagement
  gates: {
    id: string;
    name: string;
    sequence: number;  // Order in the flow
    requiredFields: string[];  // Which use case fields must be filled
    completionThreshold?: number;  // % required (default 100%)
  }[];
  
  // Who reviews/approves (optional)
  governanceBodies?: {
    name: string;
    role: string;
    gateId: string;  // Links to which gate they govern
  }[];
  
  // What "Active Portfolio" means for this engagement
  activationCriteria: 'all_gates' | 'specific_gates' | 'manual_only';
  requiredGatesForActivation?: string[];  // If specific_gates
}
This allows:

Different engagements to have different gates
Different field requirements per gate
Different gate sequences
Clear separation of Bodies (WHO) vs Gates (WHAT)


Proposed Task List for Fixes
Do you want me to create a prioritized implementation plan that addresses:

Phase 1 (Critical - Multi-tenant fixes):

Extend getConfigsFromEngagement() for value/capability configs
Add engagement-level gate configuration schema
Update gate calculation to read from engagement config


Phase 2 (UX/Logic fixes):

Auto-enable TOM when engagement has preset
Fix sequential gate % display contradiction
Auto-derive capability on use case save


Phase 3 (Architecture cleanup):

Separate Governance Bodies from Use Case Gates conceptually
Add engagement-level governanceConfig field
Update Active Portfolio filter to use engagement-scoped gates